{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/fhoerst/.conda/envs/cellvit_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "from cell_segmentation.utils.post_proc_stardist import StarDistPostProcessor\n",
    "from models.segmentation.cell_segmentation.cellvit import CellViT\n",
    "from models.segmentation.cell_segmentation.cpp_net_stardist_rn50 import up, outconv, resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.segmentation.cell_segmentation.cellvit_cpp_net import CellViTCPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'kernsel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m CellViTCPP(\n\u001b[1;32m      2\u001b[0m     \u001b[39m6\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m19\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m384\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     \u001b[39m3\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     \u001b[39m12\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     \u001b[39m6\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     [\u001b[39m3\u001b[39;49m, \u001b[39m6\u001b[39;49m, \u001b[39m9\u001b[39;49m, \u001b[39m12\u001b[39;49m]\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/histo-projects/CellViT/models/segmentation/cell_segmentation/cellvit_cpp_net.py:279\u001b[0m, in \u001b[0;36mCellViTCPP.__init__\u001b[0;34m(self, num_nuclei_classes, num_tissue_classes, embed_dim, input_channels, depth, num_heads, extract_layers, nrays, mlp_ratio, qkv_bias, drop_rate, attn_drop_rate, drop_path_rate, erosion_factors)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merosion_factors \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(erosion_factors)\n\u001b[1;32m    276\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_0_confidence \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2d(\n\u001b[1;32m    277\u001b[0m     in_channels\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, out_channels\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnrays, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    278\u001b[0m )\n\u001b[0;32m--> 279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_1_confidence \u001b[39m=\u001b[39m  nn\u001b[39m.\u001b[39;49mConv2d(\n\u001b[1;32m    280\u001b[0m     in_channels\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mlen\u001b[39;49m(erosion_factors)), \n\u001b[1;32m    281\u001b[0m     out_channels\u001b[39m=\u001b[39;49m(\u001b[39m1\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mlen\u001b[39;49m(erosion_factors)), \n\u001b[1;32m    282\u001b[0m     kernsel_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    283\u001b[0m     bias\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_features \u001b[39m=\u001b[39m SamplingFeatures(nrays\u001b[39m=\u001b[39mnrays)\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_activation_ray \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mReLU(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'kernsel_size'"
     ]
    }
   ],
   "source": [
    "CellViTCPP(\n",
    "    6,\n",
    "    19,\n",
    "    384,\n",
    "    3,\n",
    "    12,\n",
    "    6,\n",
    "    [3, 6, 9, 12]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CPPNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nrays=32, n_seg_cls=6):\n",
    "        super(CPPNet, self).__init__()\n",
    "        # Refinement\n",
    "        self.erosion_factor_list=[0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        self.sampling_feature = SamplingFeatures(nrays)\n",
    "        self.nrays = nrays\n",
    "        self.n_seg_cls = n_seg_cls\n",
    "\n",
    "        self.backbone = resnet50(True)\n",
    "        self.up1 = up(2048+1024, 1024, bilinear=True)\n",
    "        self.up2 = up(1024+512, 512, bilinear=True)\n",
    "        self.up3 = up(512+256, 256, bilinear=True)\n",
    "        self.up4 = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        \n",
    "        self.features = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.out_prob = outconv(256, 1)\n",
    "        self.out_ray = outconv(256, nrays)\n",
    "        self.conv_0_confidence = outconv(256, nrays)\n",
    "        self.conv_1_confidence = outconv(1+len(erosion_factor_list), 1+len(erosion_factor_list))\n",
    "        \n",
    "        # init\n",
    "        nn.init.constant_(self.conv_1_confidence.conv.bias, 1.0)\n",
    "\n",
    "        # upsamling\n",
    "        self.up1_seg = up(2048+1024, 1024, bilinear=True)\n",
    "        self.up2_seg = up(1024+512, 512, bilinear=True)\n",
    "        self.up3_seg = up(512+256, 256, bilinear=True)\n",
    "        self.up4_seg = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "        # self.out_seg = outconv(256, n_seg_cls)\n",
    "        #     if self.n_seg_cls == 1:\n",
    "        #         self.final_activation_seg = nn.Sigmoid()\n",
    "        #     else:\n",
    "        #         self.final_activation_seg = nn.Softmax(dim=1)\n",
    "        # self.final_activation_prob = nn.Sigmoid()\n",
    "\n",
    "        self.final_activation_ray = nn.ReLU()\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, img, gt_dist=None):\n",
    "        x1, x2, x3, x4 = self.backbone(img) # .repeat(1,3,1,1))\n",
    "        x = self.up1(x4, x3)\n",
    "        x = self.up2(x, x2)\n",
    "        x = self.up3(x, x1)\n",
    "        x = self.up4(x)\n",
    "        x = self.features(x)\n",
    "        \n",
    "        out_prob = self.out_prob(x)\n",
    "        \n",
    "        out_ray = self.out_ray(x)\n",
    "        out_ray = self.final_activation_ray(out_ray)\n",
    "\n",
    "        out_confidence = self.conv_0_confidence(x)\n",
    "\n",
    "        if gt_dist is not None:\n",
    "            out_ray_for_sampling = gt_dist\n",
    "        else:\n",
    "            out_ray_for_sampling = out_ray\n",
    "        ray_refined = [ out_ray_for_sampling ]\n",
    "\n",
    "        confidence_refined = [ out_confidence ]\n",
    "        for erosion_factor in self.erosion_factor_list:\n",
    "            base_dist = (out_ray_for_sampling-1.0)*erosion_factor\n",
    "            ray_sampled, _ = self.sampling_feature(out_ray_for_sampling, base_dist, 1)\n",
    "            conf_sampled, _ = self.sampling_feature(out_confidence, base_dist, 1)\n",
    "            ray_refined.append(ray_sampled + base_dist)\n",
    "            confidence_refined.append(conf_sampled)\n",
    "        ray_refined = torch.stack(ray_refined, dim=1)\n",
    "        b, k, c, h, w = ray_refined.shape\n",
    "\n",
    "        confidence_refined = torch.stack(confidence_refined, dim=1)\n",
    "        #confidence_refined = torch.cat((confidence_refined, ray_refined), dim=1)\n",
    "        confidence_refined = confidence_refined.permute([0,2,1,3,4]).contiguous().view(b*c, k, h, w)\n",
    "        confidence_refined = self.conv_1_confidence(confidence_refined)\n",
    "        confidence_refined = confidence_refined.view(b, c, k, h, w).permute([0,2,1,3,4])\n",
    "        confidence_refined = F.softmax(confidence_refined, dim=1)\n",
    "        if self.return_conf:\n",
    "            out_conf = [out_confidence, confidence_refined]\n",
    "        else:\n",
    "            out_conf = None\n",
    "        ray_refined = (ray_refined*confidence_refined).sum(dim=1)\n",
    "\n",
    "        out_ray = self.final_activation_ray(out_ray)\n",
    "        ray_refined = self.final_activation_ray(ray_refined)\n",
    "        out_prob = self.final_activation_prob(out_prob)\n",
    "\n",
    "        if self.with_seg:\n",
    "            x_seg = self.up1_seg(x4, x3)\n",
    "            x_seg = self.up2_seg(x_seg, x2)\n",
    "            x_seg = self.up3_seg(x_seg, x1)\n",
    "            out_seg = self.out_seg(x_seg)\n",
    "            if self.n_seg_cls == 1:\n",
    "                out_seg = self.final_activation_seg(out_seg)\n",
    "            elif not self.training:\n",
    "                out_seg = self.final_activation_seg(out_seg)\n",
    "        else:\n",
    "            out_seg = None\n",
    "\n",
    "        return [out_ray, ray_refined], [out_prob], [out_seg, ], [out_conf, ]\n",
    "\n",
    "\n",
    "    def init_weight(self):\n",
    "        for m in self.modules():        \n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if hasattr(m, 'bias'):\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.GroupNorm):\n",
    "                nn.init.constant_(m.weight, 1.0)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "        nn.init.constant_(self.conv_1_confidence.conv.bias, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellViTCPP(CellViT):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nuclei_classes: int,\n",
    "        num_tissue_classes: int,\n",
    "        embed_dim: int,\n",
    "        input_channels: int,\n",
    "        depth: int,\n",
    "        num_heads: int,\n",
    "        extract_layers: List,\n",
    "        nrays: int = 32,\n",
    "        mlp_ratio: float = 4,\n",
    "        qkv_bias: bool = True,\n",
    "        drop_rate: float = 0,\n",
    "        attn_drop_rate: float = 0,\n",
    "        drop_path_rate: float = 0,\n",
    "        # cpp-net specific \n",
    "        erosion_factors: Tuple[float] = (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "\n",
    "    ):\n",
    "        super(CellViT, self).__init__()\n",
    "        assert len(extract_layers) == 4, \"Please provide 4 layers for skip connections\"\n",
    "\n",
    "        self.patch_size = 16\n",
    "        self.num_tissue_classes = num_tissue_classes\n",
    "        self.num_nuclei_classes = num_nuclei_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        self.input_channels = input_channels\n",
    "        self.depth = depth\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.qkv_bias = qkv_bias\n",
    "        self.extract_layers = extract_layers\n",
    "        self.drop_rate = drop_rate\n",
    "        self.attn_drop_rate = attn_drop_rate\n",
    "        self.drop_path_rate = drop_path_rate\n",
    "        self.nrays = nrays\n",
    "        self.prompt_embed_dim = 256\n",
    "        \n",
    "        self.encoder = ViTCellViT(\n",
    "            patch_size=self.patch_size,\n",
    "            num_classes=self.num_tissue_classes,\n",
    "            embed_dim=self.embed_dim,\n",
    "            depth=self.depth,\n",
    "            num_heads=self.num_heads,\n",
    "            mlp_ratio=self.mlp_ratio,\n",
    "            qkv_bias=self.qkv_bias,\n",
    "            norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    "            extract_layers=self.extract_layers,\n",
    "            drop_rate=drop_rate,\n",
    "            attn_drop_rate=attn_drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "        )\n",
    "        \n",
    "        self.decoder0 = nn.Sequential(\n",
    "            Conv2DBlock(3, 32, 3, dropout=self.drop_rate),\n",
    "            Conv2DBlock(32, 64, 3, dropout=self.drop_rate),\n",
    "        )  # skip connection after positional encoding, shape should be H, W, 64\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            Deconv2DBlock(self.embed_dim, self.skip_dim_11, dropout=self.drop_rate),\n",
    "            Deconv2DBlock(self.skip_dim_11, self.skip_dim_12, dropout=self.drop_rate),\n",
    "            Deconv2DBlock(self.skip_dim_12, 128, dropout=self.drop_rate),\n",
    "        )  # skip connection 1\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            Deconv2DBlock(self.embed_dim, self.skip_dim_11, dropout=self.drop_rate),\n",
    "            Deconv2DBlock(self.skip_dim_11, 256, dropout=self.drop_rate),\n",
    "        )  # skip connection 2\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            Deconv2DBlock(self.embed_dim, self.bottleneck_dim, dropout=self.drop_rate)\n",
    "        )\n",
    "        \n",
    "        # all decoders here are without a head and return 32 features\n",
    "        self.stardist_decoder = self.create_upsampling_branch(32) \n",
    "        self.dist_decoder = self.create_upsampling_branch(32)\n",
    "        self.nuclei_type_maps_decoder = self.create_upsampling_branch(32)\n",
    "        \n",
    "        self.stardist_head = nn.Conv2d(\n",
    "            in_channels=32, in_channels=self.nrays, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.dist_head = nn.Conv2d(\n",
    "            in_channels=32, in_channels=1, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.type_head = nn.Conv2d(\n",
    "            in_channels=32, in_channels=self.num_nuclei_classes, kernel_size=1, bias=False\n",
    "        )\n",
    "        \n",
    "        self.classifier_head = (\n",
    "            nn.Linear(self.prompt_embed_dim, num_tissue_classes)\n",
    "            if num_tissue_classes > 0\n",
    "            else nn.Identity()\n",
    "        )\n",
    "\n",
    "        # cpp-net specific head\n",
    "        self.erosion_factors = list(erosion_factors)\n",
    "        self.conv_0_confidence = nn.Conv2d(\n",
    "            in_channels=32, in_channels=self.nrays, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.conv_1_confidence =  nn.Conv2d(\n",
    "            in_channels=(1 + len(erosion_factors)), \n",
    "            out_channels=(1 + len(erosion_factors)), \n",
    "            kernsel_size=1,\n",
    "            bias=True\n",
    "        )\n",
    "        self.sampling_features = SamplingFeatures(nrays=nrays)\n",
    "        self.final_activation_ray = nn.ReLU(inplace=True)\n",
    "\n",
    "        def cppnet_refine(\n",
    "        self, stardist_map: torch.Tensor, features: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Refine the stardist map and confidence map.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            stardist_map : torch.Tensor\n",
    "                The stardist map. Shape: (B, n_rays, H, W)\n",
    "            features : torch.Tensor\n",
    "                The features from the encoder. Shape: (B, C, H, W)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tuple[torch.Tensor, torch.Tensor]\n",
    "                - refined stardist map. Shape: (B, n_rays, H, W)\n",
    "                - refined confidence map. Shape: (B, C, H, W)\n",
    "        \"\"\"\n",
    "        # cppnet specific ops\n",
    "        out_confidence = self.conv_0_confidence(features) # TODO. check feature shape\n",
    "        out_ray_for_sampling = stardist_map\n",
    "\n",
    "        ray_refined = [out_ray_for_sampling]\n",
    "        confidence_refined = [out_confidence]\n",
    "\n",
    "        for erosion_factor in self.erosion_factors:\n",
    "            base_dist = (out_ray_for_sampling - 1.0) * erosion_factor\n",
    "            ray_sampled, _, _ = self.sampling_features(\n",
    "                out_ray_for_sampling, base_dist, 1\n",
    "            )\n",
    "            conf_sampled, _, _ = self.sampling_features(out_confidence, base_dist, 1)\n",
    "            ray_refined.append(ray_sampled + base_dist)\n",
    "            confidence_refined.append(conf_sampled)\n",
    "        ray_refined = torch.stack(ray_refined, dim=1)\n",
    "        b, k, c, h, w = ray_refined.shape\n",
    "\n",
    "        confidence_refined = torch.stack(confidence_refined, dim=1)\n",
    "        confidence_refined = (\n",
    "            confidence_refined.permute([0, 2, 1, 3, 4])\n",
    "            .contiguous()\n",
    "            .view(b * c, k, h, w)\n",
    "        )\n",
    "        confidence_refined = self.conv_1_confidence(confidence_refined)\n",
    "        confidence_refined = confidence_refined.view(b, c, k, h, w).permute(\n",
    "            [0, 2, 1, 3, 4]\n",
    "        )\n",
    "        confidence_refined = F.softmax(confidence_refined, dim=1)\n",
    "\n",
    "        ray_refined = (ray_refined * confidence_refined).sum(dim=1)\n",
    "        ray_refined = self.final_activation_ray(ray_refined)\n",
    "\n",
    "        return ray_refined, confidence_refined\n",
    "    \n",
    "\n",
    "    def forward(self, x: torch.Tensor, retrieve_tokens: bool = False):\n",
    "        assert (\n",
    "            x.shape[-2] % self.patch_size == 0\n",
    "        ), \"Img must have a shape of that is divisble by patch_soze (token_size)\"\n",
    "        assert (\n",
    "            x.shape[-1] % self.patch_size == 0\n",
    "        ), \"Img must have a shape of that is divisble by patch_soze (token_size)\"\n",
    "        \n",
    "        classifier_logits, _, z = self.encoder(x)\n",
    "\n",
    "        z0, z1, z2, z3, z4 = x, *z\n",
    "\n",
    "        # performing reshape for the convolutional layers and upsampling (restore spatial dimension)\n",
    "        patch_dim = [int(d / self.patch_size) for d in [x.shape[-2], x.shape[-1]]]\n",
    "        z4 = z4[:, 1:, :].transpose(-1, -2).view(-1, self.embed_dim, *patch_dim)\n",
    "        z3 = z3[:, 1:, :].transpose(-1, -2).view(-1, self.embed_dim, *patch_dim)\n",
    "        z2 = z2[:, 1:, :].transpose(-1, -2).view(-1, self.embed_dim, *patch_dim)\n",
    "        z1 = z1[:, 1:, :].transpose(-1, -2).view(-1, self.embed_dim, *patch_dim)\n",
    "        \n",
    "        stardist_features = self._forward_upsample(\n",
    "            z0, z1, z2, z3, z4, self.stardist_decoder\n",
    "        )\n",
    "        dist_map_features = self._forward_upsample(\n",
    "            z0, z1, z2, z3, z4, self.dist_decoder\n",
    "        )\n",
    "        type_map_features = self._forward_upsample(\n",
    "            z0, z1, z2, z3, z4, self.dist_decoder\n",
    "        )\n",
    "        \n",
    "        stardist_head_out = self.stardist_head(stardist_features)\n",
    "        dist_map_head_out = self.dist_head(dist_map_features)\n",
    "        type_map_head_out = self.type_head(type_map_features)\n",
    "        \n",
    "        ray_refined, confidence_refined = self.cppnet_refine(\n",
    "            stardist_head_out, stardist_features\n",
    "        )\n",
    "        \n",
    "        out_dict = {\n",
    "            \"stardist_map\": stardist_head_out,\n",
    "            \"stardist_refined\": ray_refined,\n",
    "            \"confidence_refined\": confidence_refined,\n",
    "            \"dist_map_head_out\": dist_map_head_out,\n",
    "            \"type_map_head_out\": type_map_head_out,\n",
    "            \"tissue_types\": classifier_logits\n",
    "        }\n",
    "        \n",
    "        if retrieve_tokens:\n",
    "            out_dict[\"tokens\"] = z4\n",
    "\n",
    "        return out_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellvit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
